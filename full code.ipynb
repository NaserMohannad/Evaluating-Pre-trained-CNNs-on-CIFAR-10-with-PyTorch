{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch torchvision matplotlib tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport torchvision.models as models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:32:29.864240Z","iopub.execute_input":"2024-12-28T18:32:29.864585Z","iopub.status.idle":"2024-12-28T18:32:33.886444Z","shell.execute_reply.started":"2024-12-28T18:32:29.864559Z","shell.execute_reply":"2024-12-28T18:32:33.885779Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# transformations","metadata":{}},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:32:38.898326Z","iopub.execute_input":"2024-12-28T18:32:38.898624Z","iopub.status.idle":"2024-12-28T18:32:38.902657Z","shell.execute_reply.started":"2024-12-28T18:32:38.898600Z","shell.execute_reply":"2024-12-28T18:32:38.901835Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Load CIFAR-10 Dataset","metadata":{}},{"cell_type":"code","source":"train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntest_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:32:43.255504Z","iopub.execute_input":"2024-12-28T18:32:43.255828Z","iopub.status.idle":"2024-12-28T18:32:51.571737Z","shell.execute_reply.started":"2024-12-28T18:32:43.255801Z","shell.execute_reply":"2024-12-28T18:32:51.571056Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:04<00:00, 35136492.85it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# Dataloaders\n","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:32:58.841679Z","iopub.execute_input":"2024-12-28T18:32:58.842010Z","iopub.status.idle":"2024-12-28T18:32:58.845876Z","shell.execute_reply.started":"2024-12-28T18:32:58.841980Z","shell.execute_reply":"2024-12-28T18:32:58.844988Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:33:20.352977Z","iopub.execute_input":"2024-12-28T18:33:20.353310Z","iopub.status.idle":"2024-12-28T18:33:20.356972Z","shell.execute_reply.started":"2024-12-28T18:33:20.353285Z","shell.execute_reply":"2024-12-28T18:33:20.356211Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Function to modify the final layer of the model","metadata":{}},{"cell_type":"code","source":"def modify_model(model, num_classes):\n        if hasattr(model, 'fc'):\n            num_ftrs = model.fc.in_features\n            model.fc = nn.Linear(num_ftrs, num_classes)\n        elif hasattr(model, 'classifier'):\n            if isinstance(model.classifier, nn.Sequential):\n                num_ftrs = model.classifier[-1].in_features\n                model.classifier[-1] = nn.Linear(num_ftrs, num_classes)\n            else:\n                num_ftrs = model.classifier.in_features\n                model.classifier = nn.Linear(num_ftrs, num_classes)\n        return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T19:48:16.207495Z","iopub.execute_input":"2024-12-28T19:48:16.207983Z","iopub.status.idle":"2024-12-28T19:48:16.212906Z","shell.execute_reply.started":"2024-12-28T19:48:16.207935Z","shell.execute_reply":"2024-12-28T19:48:16.212041Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Function to train the model\n","metadata":{}},{"cell_type":"code","source":"def train_model(model, train_loader, criterion, optimizer, device, epochs=5):\n    model.train()\n    for epoch in range(epochs):\n        running_loss = 0.0\n        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n            images, labels = images.to(device), labels.to(device)\n\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n        print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:33:39.022918Z","iopub.execute_input":"2024-12-28T18:33:39.023258Z","iopub.status.idle":"2024-12-28T18:33:39.028388Z","shell.execute_reply.started":"2024-12-28T18:33:39.023232Z","shell.execute_reply":"2024-12-28T18:33:39.027370Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# Function to evaluate the model\n","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model, test_loader, device):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    accuracy = 100 * correct / total\n    print(f\"Test Accuracy: {accuracy:.2f}%\")\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:33:48.362051Z","iopub.execute_input":"2024-12-28T18:33:48.362365Z","iopub.status.idle":"2024-12-28T18:33:48.367271Z","shell.execute_reply.started":"2024-12-28T18:33:48.362343Z","shell.execute_reply":"2024-12-28T18:33:48.366416Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# List of models to train\n","metadata":{}},{"cell_type":"code","source":"models_to_train = [\n    (\"ResNet18\", models.resnet18(pretrained=True)),\n    (\"VGG16\", models.vgg16(pretrained=True)),\n    (\"MobileNetV2\", models.mobilenet_v2(pretrained=True))\n]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:34:09.856698Z","iopub.execute_input":"2024-12-28T18:34:09.857016Z","iopub.status.idle":"2024-12-28T18:34:15.139412Z","shell.execute_reply.started":"2024-12-28T18:34:09.856994Z","shell.execute_reply":"2024-12-28T18:34:15.138516Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 81.1MB/s]\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n100%|██████████| 528M/528M [00:02<00:00, 225MB/s] \n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n100%|██████████| 13.6M/13.6M [00:00<00:00, 81.3MB/s]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"results = []\n\nfor model_name, model in models_to_train:\n    print(f\"\\nTraining {model_name}...\")\n    model = modify_model(model, num_classes=10)\n    model = model.to(device)\n\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    train_model(model, train_loader, criterion, optimizer, device, epochs=5)\n\n    accuracy = evaluate_model(model, test_loader, device)\n    results.append((model_name, accuracy))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T18:34:23.217710Z","iopub.execute_input":"2024-12-28T18:34:23.218000Z","iopub.status.idle":"2024-12-28T19:40:28.309408Z","shell.execute_reply.started":"2024-12-28T18:34:23.217977Z","shell.execute_reply":"2024-12-28T19:40:28.308491Z"}},"outputs":[{"name":"stdout","text":"\nTraining ResNet18...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 1563/1563 [02:24<00:00, 10.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.6822\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 1563/1563 [02:23<00:00, 10.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.3985\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 1563/1563 [02:23<00:00, 10.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.2867\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 1563/1563 [02:22<00:00, 10.97it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 0.2116\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 1563/1563 [02:22<00:00, 11.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 0.1563\nTest Accuracy: 88.50%\n\nTraining VGG16...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 1563/1563 [07:31<00:00,  3.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 1.8004\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 1563/1563 [07:32<00:00,  3.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 1.3913\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 1563/1563 [07:31<00:00,  3.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 1.2356\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 1563/1563 [07:32<00:00,  3.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 1.1525\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 1563/1563 [07:32<00:00,  3.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 1.0378\nTest Accuracy: 63.51%\n\nTraining MobileNetV2...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1/5: 100%|██████████| 1563/1563 [03:03<00:00,  8.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Loss: 0.6410\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/5: 100%|██████████| 1563/1563 [03:03<00:00,  8.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Loss: 0.4245\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/5: 100%|██████████| 1563/1563 [03:03<00:00,  8.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Loss: 0.3570\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/5: 100%|██████████| 1563/1563 [03:03<00:00,  8.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4, Loss: 0.3128\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5/5: 100%|██████████| 1563/1563 [03:03<00:00,  8.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5, Loss: 0.2755\nTest Accuracy: 89.28%\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"# Accuracy Table ","metadata":{}},{"cell_type":"markdown","source":"| **Model**           | **Test Accuracy (%)** |\n|----------------------|-----------------------|\n| ResNet18            | 88.50%                  |\n| VGG16               | 63.51%                  |\n| MobileNetV2         | 89.28%                  |","metadata":{}}]}