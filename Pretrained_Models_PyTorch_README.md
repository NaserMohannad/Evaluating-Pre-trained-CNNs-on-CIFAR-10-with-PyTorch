# Using Pre-trained Vision Models with PyTorch

This project evaluates multiple pre-trained convolutional neural networks from `torchvision.models` on image classification tasks using the CIFAR-10 dataset. The aim is to compare model performance and training behavior in a unified setup.

---

## ğŸ¯ Objective

- Load and adapt pre-trained models (ResNet18, VGG16, MobileNetV2)
- Modify their final layers to fit CIFAR-10 (10 classes)
- Train each model for 5 epochs
- Evaluate and compare performance based on test accuracy

---

## ğŸ§  Models Used

- âœ… ResNet18
- âœ… VGG16
- âœ… MobileNetV2

All models were modified by replacing the final fully connected (FC) layer.

---

## ğŸ§ª Dataset

- **Dataset**: CIFAR-10
- **Input shape**: Resized to 224Ã—224
- **Transforms**:
  - `transforms.Resize((224, 224))`
  - `transforms.ToTensor()`
  - `transforms.Normalize(mean, std)`

---

## âš™ï¸ Training Configuration

- **Loss Function**: CrossEntropyLoss
- **Optimizer**: Adam
- **Learning Rate**: 0.001
- **Batch Size**: 32
- **Epochs**: 5
- **Device**: GPU when available (e.g., Kaggle, Colab)

---

## ğŸ“ Files

- `assignment-3.ipynb`: Full implementation and results
- `deep_learning_assignment.pdf`: Project requirements and instructions

---

## ğŸ“Œ Notes

- All training loops include tqdm progress bars
- Each model was trained independently and fairly
- Reproducible using PyTorch and torchvision
